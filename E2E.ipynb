{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2E NLG Challenge\n",
    "\n",
    "This is a sequece2sequence model transfering meaning representations(MR) of a restaurant into a description in natural language(NL). Pytorch is used to build up the seq2seq neural model.\n",
    "\n",
    "This is based on [this tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) by Sean Robertson from the PyTorch website. It has been modified by Katy Ilonka Gero for COMS W4705 taught at Columbia University by Professor Kathy McKeown.\n",
    "\n",
    "### Overview\n",
    "\n",
    "The aim of this jupyter notebook is to:\n",
    "\n",
    "1. train a model on the E2E restaurant data set on a GPU\n",
    "2. implement beam search for evaluation\n",
    "3. implement a BLEU evaluator and report BLEU scores\n",
    "\n",
    "In this dataset, the inputs are restaurant meaning representations, which are a series of key-value pairs that encode information about a restaurant. The outputs are fluent sentences that describe the restaurant. Here is an example:\n",
    "\n",
    "*Input: Meaning Representation*\n",
    "\n",
    "```\n",
    "name[The Eagle],\n",
    "eatType[coffee shop],\n",
    "food[French],\n",
    "priceRange[moderate],\n",
    "customerRating[3/5],\n",
    "area[riverside],\n",
    "kidsFriendly[yes],\n",
    "near[Burger King]\n",
    "```\n",
    "\n",
    "*Output: Fluent Sentence*\n",
    "\n",
    "```\n",
    "The three star coffee shop, The Eagle, gives families a mid-priced dining experience featuring a variety of wines and cheeses. Find The Eagle near Burger King.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is useful for checking if you are successfully using the GPU\n",
    "\n",
    "mydevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mydevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the length filter\n",
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= MAX_LEN and len(example.tgt) <= MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the e2e data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE E2E DATA HERE\n",
    "\n",
    "train_path = 'data/e2e-dataset/trainset.csv'\n",
    "dev_path = 'data/e2e-dataset/devset.csv'\n",
    "\n",
    "src = torchtext.data.Field(\n",
    "    batch_first=True, \n",
    "    include_lengths=True\n",
    "    )\n",
    "tgt = torchtext.data.Field(\n",
    "    batch_first=True, \n",
    "    preprocessing = lambda seq: [SOS_TOKEN] + seq + [EOS_TOKEN]\n",
    "    )\n",
    "\n",
    "data_train = torchtext.data.TabularDataset(\n",
    "        path=train_path, format='csv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "data_dev = torchtext.data.TabularDataset(\n",
    "        path=dev_path, format='csv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the vocab and some example data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 tokens from input vocab:\n",
      " ['<unk>', '<pad>', 'customer', 'name[The', 'of', 'area[riverside],', 'out', '5],', 'eatType[coffee', 'shop],', 'than', 'familyFriendly[yes]', 'familyFriendly[yes],', 'area[city', 'eatType[pub],', 'centre],', 'food[Japanese],', 'food[Italian],', 'food[Fast', 'food],']\n",
      "\n",
      "20 tokens from output vocab:\n",
      " ['<unk>', '<pad>', 'is', '<eos>', '<sos>', 'a', 'The', 'the', 'in', 'near', 'of', 'and', 'food', 'customer', 'located', 'It', 'restaurant', 'has', 'coffee', 'price']\n",
      "\n",
      "num training examples: 42038\n",
      "\n",
      "example train data:\n",
      "src:\n",
      " ['name[The', 'Waterman],', 'food[Italian],', 'priceRange[high],', 'customer', 'rating[average],', 'area[city', 'centre],', 'familyFriendly[yes]']\n",
      "tgt:\n",
      " ['<sos>', 'The', 'Waterman', 'is', 'a', 'children', 'friendly', 'Italian', 'restaurant', 'in', 'the', 'city', 'centre', 'that', 'has', 'an', 'average', 'rating', 'and', 'high', 'prices.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "src.build_vocab(data_train, max_size=50000)\n",
    "tgt.build_vocab(data_train, max_size=50000)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab\n",
    "\n",
    "print('20 tokens from input vocab:\\n', list(input_vocab.stoi.keys())[:20])\n",
    "print('\\n20 tokens from output vocab:\\n', list(output_vocab.stoi.keys())[:20])\n",
    "\n",
    "print('\\nnum training examples:', len(data_train.examples))\n",
    "\n",
    "item = random.choice(data_train.examples)\n",
    "print('\\nexample train data:')\n",
    "print('src:\\n', item.src)\n",
    "print('tgt:\\n', item.tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, myinput, hidden):\n",
    "        embedded = self.embedding(myinput).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=mydevice)\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\n",
    "          max_length=MAX_LEN, teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    # get an initial hidden state for the encoder\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    # zero the gradients of the optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # get the seq lengths, used for iterating through encoder/decoder\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    # create empty tensor to fill with encoder outputs\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
    "\n",
    "    # create a variable for loss\n",
    "    loss = 0\n",
    "    \n",
    "    # pass the inputs through the encoder\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # create a start-of-sequence tensor for the decoder\n",
    "    decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
    "\n",
    "    # set the decoder hidden state to the final encoder hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # decide if we will use teacher forcing\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        \n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "                \n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            decoder_input = target_tensor[di]\n",
    "        \n",
    "        if decoder_input.item() == output_vocab.stoi[EOS_TOKEN]:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01, teacher_forcing_ratio=0.5):\n",
    "    print(f'Running {n_iters} epochs...')\n",
    "    print_loss_total = 0\n",
    "    print_loss_epoch = 0\n",
    "\n",
    "    encoder_optim = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optim = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # note batch size of 1, just for simplicity\n",
    "    # DO NOT INCREASE THE BATCH SIZE\n",
    "    batch_iterator = torchtext.data.Iterator(\n",
    "        dataset=data_train, batch_size=1,\n",
    "        sort=False, sort_within_batch=True,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        device=mydevice, repeat=False)\n",
    "    \n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for e in range(n_iters):\n",
    "        batch_generator = batch_iterator.__iter__()\n",
    "        step = 0\n",
    "        start = time.time()\n",
    "        for batch in batch_generator:\n",
    "            step += 1\n",
    "            \n",
    "            # get the input and target from the batch iterator\n",
    "            input_tensor, input_lengths = getattr(batch, 'src')\n",
    "            target_tensor = getattr(batch, 'tgt')\n",
    "            \n",
    "            # this is because we're not actually using the batches.\n",
    "            # batch size is 1 and this just selects that first one\n",
    "            input_tensor = input_tensor[0]\n",
    "            target_tensor = target_tensor[0]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optim, decoder_optim, criterion, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            print_loss_total += loss\n",
    "            print_loss_epoch += loss\n",
    "            \n",
    "\n",
    "            if step % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                t = (time.time() - start) / 60\n",
    "                print(f'step: {step}\\t avg loss: {print_loss_avg:.2f}\\t time for {print_every} steps: {t:.2f} min')\n",
    "                start = time.time()\n",
    "        \n",
    "        print_loss_avg = print_loss_epoch / step\n",
    "        print_loss_epoch = 0\n",
    "        print(f'End of epoch {e}, avg loss {print_loss_avg:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "encoder1 = EncoderRNN(len(input_vocab), hidden_size).to(mydevice)\n",
    "decoder1 = DecoderRNN(hidden_size, len(output_vocab)).to(mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 epochs...\n",
      "step: 1000\t avg loss: 4.34\t time for 1000 steps: 0.45 min\n",
      "step: 2000\t avg loss: 3.53\t time for 1000 steps: 0.43 min\n",
      "step: 3000\t avg loss: 3.34\t time for 1000 steps: 0.42 min\n",
      "step: 4000\t avg loss: 3.23\t time for 1000 steps: 0.42 min\n",
      "step: 5000\t avg loss: 3.14\t time for 1000 steps: 0.43 min\n",
      "step: 6000\t avg loss: 3.02\t time for 1000 steps: 0.43 min\n",
      "step: 7000\t avg loss: 2.93\t time for 1000 steps: 0.43 min\n",
      "step: 8000\t avg loss: 2.84\t time for 1000 steps: 0.44 min\n",
      "step: 9000\t avg loss: 2.88\t time for 1000 steps: 0.43 min\n",
      "step: 10000\t avg loss: 2.82\t time for 1000 steps: 0.43 min\n",
      "step: 11000\t avg loss: 2.81\t time for 1000 steps: 0.43 min\n",
      "step: 12000\t avg loss: 2.77\t time for 1000 steps: 0.43 min\n",
      "step: 13000\t avg loss: 2.76\t time for 1000 steps: 0.43 min\n",
      "step: 14000\t avg loss: 2.64\t time for 1000 steps: 0.42 min\n",
      "step: 15000\t avg loss: 2.71\t time for 1000 steps: 0.43 min\n",
      "step: 16000\t avg loss: 2.65\t time for 1000 steps: 0.44 min\n",
      "step: 17000\t avg loss: 2.58\t time for 1000 steps: 0.42 min\n",
      "step: 18000\t avg loss: 2.55\t time for 1000 steps: 0.43 min\n",
      "step: 19000\t avg loss: 2.51\t time for 1000 steps: 0.43 min\n",
      "step: 20000\t avg loss: 2.53\t time for 1000 steps: 0.43 min\n",
      "step: 21000\t avg loss: 2.57\t time for 1000 steps: 0.44 min\n",
      "step: 22000\t avg loss: 2.49\t time for 1000 steps: 0.43 min\n",
      "step: 23000\t avg loss: 2.48\t time for 1000 steps: 0.43 min\n",
      "step: 24000\t avg loss: 2.48\t time for 1000 steps: 0.44 min\n",
      "step: 25000\t avg loss: 2.42\t time for 1000 steps: 0.43 min\n",
      "step: 26000\t avg loss: 2.41\t time for 1000 steps: 0.43 min\n",
      "step: 27000\t avg loss: 2.51\t time for 1000 steps: 0.43 min\n",
      "step: 28000\t avg loss: 2.41\t time for 1000 steps: 0.43 min\n",
      "step: 29000\t avg loss: 2.41\t time for 1000 steps: 0.43 min\n",
      "step: 30000\t avg loss: 2.38\t time for 1000 steps: 0.43 min\n",
      "step: 31000\t avg loss: 2.43\t time for 1000 steps: 0.43 min\n",
      "step: 32000\t avg loss: 2.43\t time for 1000 steps: 0.43 min\n",
      "step: 33000\t avg loss: 2.37\t time for 1000 steps: 0.43 min\n",
      "step: 34000\t avg loss: 2.39\t time for 1000 steps: 0.43 min\n",
      "step: 35000\t avg loss: 2.42\t time for 1000 steps: 0.43 min\n",
      "step: 36000\t avg loss: 2.41\t time for 1000 steps: 0.43 min\n",
      "step: 37000\t avg loss: 2.32\t time for 1000 steps: 0.44 min\n",
      "step: 42000\t avg loss: 2.38\t time for 1000 steps: 0.43 min\n",
      "End of epoch 0, avg loss 2.66\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, decoder1, 1, print_every=1000, teacher_forcing_ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving and loading the model\n",
    "torch.save(encoder1.state_dict(), 'encoder.mdl')\n",
    "torch.save(decoder1.state_dict(), 'decoder.mdl')\n",
    "\n",
    "hidden_size = 128\n",
    "encoder1 = EncoderRNN(len(input_vocab), hidden_size).to(mydevice)\n",
    "decoder1 = DecoderRNN(hidden_size, len(output_vocab)).to(mydevice)\n",
    "encoder1.load_state_dict(torch.load('encoder.mdl'))\n",
    "decoder1.load_state_dict(torch.load('decoder.mdl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using Greedy Search Algorithm Decoder\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LEN):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor([input_vocab.stoi[word] for word in sentence], device=mydevice)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            next_word = output_vocab.itos[topi.item()]\n",
    "            decoded_words.append(next_word)\n",
    "            if next_word == EOS_TOKEN:\n",
    "                break\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement beam search evaluator\n",
    "\n",
    "Be sure to return all the output sequences (i.e. if the beam size is k, you should return k sequences) and their associated probabilities. You will need the associated probabilities to select the best performing sequence when calculating BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using Beam Search Decoder\n",
    "\n",
    "# The output of next cell should be an example input from the dev set, \n",
    "# and three outputs from a beam search evaluator.\n",
    "\n",
    "def beam_search_evaluate(encoder, decoder, sentence, max_length=MAX_LEN, k = 3):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor([input_vocab.stoi[word] for word in sentence], device=mydevice)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        seq_list = [([],0,decoder_input,decoder_hidden)]\n",
    "        alpha = .8    ###parameter for length penalty\n",
    "        for di in range(max_length):\n",
    "            cand = []\n",
    "            for seq, score, decoder_input,decoder_hidden in seq_list:\n",
    "                if output_vocab.itos[decoder_input] != EOS_TOKEN: \n",
    "                    for i in range(k):                   \n",
    "                        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                        topv, topi = decoder_output.data.topk(k)\n",
    "                        value = topv[0][i]\n",
    "                        idx = topi[0][i]\n",
    "                        lp = (5+len(seq)+1)**alpha/(5+1)**alpha\n",
    "                        cand.append(tuple([seq+[output_vocab.itos[idx]], (score+value)/lp, idx.squeeze().detach(), decoder_hidden]))\n",
    "                else:\n",
    "                    lp = lp = (5+len(seq))**alpha/(5+1)**alpha\n",
    "                    cand.append(tuple([seq, (score+value)/lp, decoder_input, decoder_hidden]))\n",
    "            ordered = sorted(cand, key=lambda tup:tup[1], reverse = True)\n",
    "            seq_list = ordered[:k]\n",
    "\n",
    "        return [l[0] for l in seq_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name[Fitzbillies],', 'eatType[coffee', 'shop],', 'food[Chinese],', 'priceRange[cheap],', 'customer', 'rating[average],', 'area[riverside],', 'familyFriendly[no]']\n",
      "<sos> Fitzbillies is an inexpensive coffee shop that provides Chinese food in the cheap price range. It is located in the riverside. It is not family friendly and has an average customer rating. It has an average customer rating and has an average customer rating and has an average customer rating and has a low price range. It is located in the riverside area. <eos>\n",
      "<sos> Fitzbillies is an inexpensive coffee shop that provides Chinese food in the cheap price range. It is located in the riverside. It is not family friendly and has an average customer rating. It has an average customer rating and has an average customer rating and has an average customer rating and has a low price range. are located in the riverside area. <eos>\n",
      "<sos> Fitzbillies is an inexpensive coffee shop that provides Chinese food in the cheap price range. It is located in the riverside. It is not family friendly and has an average customer rating. It has an average customer rating and has an average customer rating and has an average customer rating and has a low price range. It has a low customer rating. <eos>\n",
      "\n",
      "['name[Aromi],', 'eatType[coffee', 'shop],', 'food[Chinese],', 'customer', 'rating[average],', 'area[city', 'centre],', 'familyFriendly[no]']\n",
      "<sos> Aromi is an adult only coffee shop serving Chinese food in the city centre. It has a low customer rating and is not family-friendly. <eos>\n",
      "<sos> Aromi is an adult only coffee shop serving Chinese food in the city centre. It has an average customer rating and is not family-friendly. <eos>\n",
      "<sos> Aromi is an adult only coffee shop serving Chinese food in the city centre. It has a customer rating of 1 out of 5. <eos>\n",
      "\n",
      "['name[The', 'Wrestlers],', 'eatType[coffee', 'shop],', 'food[English],', 'priceRange[less', 'than', '£20],', 'area[riverside],', 'familyFriendly[no],', 'near[Raja', 'Indian', 'Cuisine]']\n",
      "<sos> The Mill is a coffee shop located near Raja Indian Cuisine in the riverside area and is not family friendly and has a price range of less than £20. <eos>\n",
      "<sos> The Mill is a coffee shop located near Raja Indian Cuisine in the riverside area and is not family friendly and has a price range of less than £20. <eos>\n",
      "<sos> The Mill is a coffee shop located near Raja Indian Cuisine in the riverside area and is not family friendly and has a price range of less than 20. <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Beam Search Output Examples\n",
    "for i in range(3):\n",
    "    item = random.choice(data_dev.examples)\n",
    "    seq = item.src\n",
    "    print(seq)\n",
    "    beam_res = beam_search_evaluate(encoder1, decoder1, seq, max_length = 70, k = 3)\n",
    "    for words in beam_res:\n",
    "        print(' '.join(words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name[The', 'Phoenix],', 'food[Indian],', 'priceRange[£20-25],', 'customer', 'rating[high],', 'area[city', 'centre]']\n",
      "<sos> The Phoenix serves Indian food in the high price range. It is located in the city centre. <eos>\n",
      "\n",
      "['name[Cotto],', 'food[Indian],', 'customer', 'rating[1', 'out', 'of', '5],', 'familyFriendly[yes],', 'near[Ranch]']\n",
      "<sos> Cotto is a Indian restaurant that serves Indian food It is friendly rating and is <eos>\n",
      "\n",
      "['name[Midsummer', 'House],', 'food[Fast', 'food],', 'priceRange[cheap],', 'customer', 'rating[5', 'out', 'of', '5],', 'near[All', 'Bar', 'One]']\n",
      "<sos> Midsummer House is a cheap restaurant Bar near All Bar One. One. <eos>\n",
      "\n",
      "['name[The', 'Mill],', 'eatType[pub],', 'food[English],', 'priceRange[high],', 'area[city', 'centre]']\n",
      "<sos> The Mill is a pub located in the city centre. <eos>\n",
      "\n",
      "['name[The', 'Golden', 'Palace],', 'eatType[coffee', 'shop],', 'food[Japanese],', 'priceRange[moderate],', 'customer', 'rating[1', 'out', 'of', '5],', 'area[riverside]']\n",
      "<sos> The Golden Palace is a coffee shop shop coffee shop shop shop shop located in the <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This selects 5 random datapoints from the training data and shows the generated sequence\n",
    "\n",
    "for i in range(5):\n",
    "    item = random.choice(data_train.examples)\n",
    "    seq = item.src\n",
    "    print(seq)\n",
    "    words = evaluate(encoder1, decoder1, seq)\n",
    "    print(' '.join(words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement BLEU evaluator\n",
    "\n",
    "Remember that when calculating BLEU using beam search, select the top-scoring sequence output using the model probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE BLEU EVALUATION HERE\n",
    "\n",
    "# The output of next 2 cells should be the average BLEU score on the dev set\n",
    "# for greedy decoding AND for beam search decoding (beam size = 3)\n",
    "import numpy as np\n",
    "\n",
    "###Find all the references\n",
    "def get_ref_list(src):\n",
    "    ref_list = []\n",
    "    for e in data_dev.examples:\n",
    "        if e.src == list(src):\n",
    "            ref_list.append(e.tgt)\n",
    "    return(ref_list)\n",
    "\n",
    "###Model Output (Candidate)\n",
    "def get_cand(src, decoder_type = \"beam\"):\n",
    "    if decoder_type == \"beam\":\n",
    "        cand = beam_search_evaluate(encoder1, decoder1, src, max_length = 100, k = 3)[0]\n",
    "    else:\n",
    "        cand = evaluate(encoder1, decoder1, src)\n",
    "    return(cand)\n",
    "\n",
    "###Calculate the BLEU score\n",
    "def get_score(src, decoder_type, ngram):\n",
    "    cand = get_cand(src, decoder_type)\n",
    "    p_list = []\n",
    "    ref_list = get_ref_list(src)\n",
    "    \n",
    "    #n-gram\n",
    "    for n in range(1,ngram + 1):\n",
    "        ref_vocab_list = []\n",
    "\n",
    "        ###Build up n-gram dict for all the references\n",
    "        for ref in ref_list:\n",
    "            ref_vocab = dict()\n",
    "            for i in range(len(ref)-n+1):\n",
    "                s = tuple(ref[i:(i+n)])\n",
    "                if ref_vocab.get(s):\n",
    "                    ref_vocab[s] += 1\n",
    "                else:\n",
    "                    ref_vocab.update({s:1})\n",
    "            ref_vocab_list.append(ref_vocab)\n",
    "\n",
    "        ###Build up n-gram dict for the candidate\n",
    "        cand_vocab = dict()\n",
    "        for i in range(len(cand)-n+1):\n",
    "            s = tuple(cand[i:(i+n)])\n",
    "            if cand_vocab.get(s):\n",
    "                cand_vocab[s] += 1\n",
    "            else:\n",
    "                cand_vocab.update({s:1})\n",
    "\n",
    "        ###Calculate n-gram precision\n",
    "        numerator = 0\n",
    "        for s in cand_vocab:\n",
    "            max_ref = max([ref_vocab.get(s) if ref_vocab.get(s) else 0 for ref_vocab in ref_vocab_list])\n",
    "            max_ref = max_ref if max_ref else 0\n",
    "            numerator += max_ref\n",
    "        p = numerator/(len(cand)-n+1)\n",
    "        if n > 1 and p == 0:\n",
    "            p = p_list[-1]\n",
    "        p_list.append(p)\n",
    "    \n",
    "    ###Brevity Penalty\n",
    "    c = len(cand)\n",
    "    len_list = np.array([len(ref) for ref in ref_list])\n",
    "    r = len_list[np.argmin(abs(len_list-c))]\n",
    "    BP = max(1,np.exp(1-r/c))\n",
    "    return BP * np.exp(np.mean(np.log(p_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 out of 547 completed\n",
      "200 out of 547 completed\n",
      "300 out of 547 completed\n",
      "400 out of 547 completed\n",
      "500 out of 547 completed\n",
      "All completed!\n",
      "0.4760110725346942\n"
     ]
    }
   ],
   "source": [
    "###BLEU score for beam search\n",
    "src_unique = list(set([tuple(e.src) for e in data_dev.examples[1:]]))\n",
    "BLEU_score = []\n",
    "decoder_type = \"beam\"\n",
    "ngram = 4\n",
    "\n",
    "for i, src in enumerate(src_unique):\n",
    "    BLEU_score.append(get_score(src, decoder_type, ngram))\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(\"{0} out of {1} completed\".format(i+1, len(src_unique)))\n",
    "print(\"All completed!\")\n",
    "print(np.mean(BLEU_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 out of 547 completed\n",
      "200 out of 547 completed\n",
      "300 out of 547 completed\n",
      "400 out of 547 completed\n",
      "500 out of 547 completed\n",
      "All completed!\n",
      "0.5236403261617786\n"
     ]
    }
   ],
   "source": [
    "###BLEU score for greedy search\n",
    "greedy_BLEU_score = []\n",
    "decoder_type = \"greedy\"\n",
    "ngram = 4\n",
    "\n",
    "for i, src in enumerate(src_unique):\n",
    "    greedy_BLEU_score.append(get_score(src, decoder_type, ngram))\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(\"{0} out of {1} completed\".format(i+1, len(src_unique)))\n",
    "print(\"All completed!\")\n",
    "print(np.mean(greedy_BLEU_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('name[The', 'Cambridge', 'Blue],', 'eatType[coffee', 'shop],', 'customer', 'rating[1', 'out', 'of', '5],', 'area[riverside],', 'familyFriendly[yes],', 'near[Burger', 'King]')\n",
      "<sos> The Eagle coffee shop is located near Burger King and has a customer rating of 1 out of 5. It is family friendly and is located in the riverside area. <eos>\n",
      "\n",
      "('name[The', 'Cricketers],', 'eatType[coffee', 'shop],', 'food[English],', 'customer', 'rating[3', 'out', 'of', '5],', 'familyFriendly[yes],', 'near[The', 'Portland', 'Arms]')\n",
      "<sos> Near The Portland Arms, The Cricketers is a coffee shop that also kid friendly and has a 3 out of 5 customer rating. <eos>\n",
      "\n",
      "('name[Browns', 'Cambridge],', 'eatType[coffee', 'shop],', 'food[Chinese],', 'customer', 'rating[average],', 'area[riverside],', 'familyFriendly[yes],', 'near[Crowne', 'Plaza', 'Hotel]')\n",
      "<sos> Near the Crowne Plaza Hotel in the riverside area is a family friendly coffee shop serving Chinese food. It has an average customer rating and is family friendly. <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### For Error Analysis: Unseen Restaurant names\n",
    "for idx in [10, 25, 300]:\n",
    "    print(src_unique[idx])\n",
    "    print(' '.join(get_cand(src_unique[idx], decoder_type = \"beam\")))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('name[Fitzbillies],', 'eatType[coffee', 'shop],', 'food[English],', 'priceRange[£20-25],', 'customer', 'rating[high],', 'area[city', 'centre],', 'familyFriendly[yes]')\n",
      "Geedy Search:\n",
      "<sos> Fitzbillies is a coffee shop shop in the city a price is <eos>\n",
      "0.3383890558271442\n",
      "Beam Search:\n",
      "<sos> Fitzbillies has a high price range and is a child friendly coffee shop. It has an average customer rating and is located in the city centre. <eos>\n",
      "0.2833593223209699\n",
      "\n",
      "('name[The', 'Golden', 'Palace],', 'eatType[coffee', 'shop],', 'food[Chinese],', 'priceRange[more', 'than', '£30],', 'customer', 'rating[high],', 'area[city', 'centre]')\n",
      "Geedy Search:\n",
      "<sos> The Golden Palace is a high priced coffee shop located in the city Golden and serves high <eos>\n",
      "0.5782419324934458\n",
      "Beam Search:\n",
      "There is a high priced coffee shop located in the city centre that serves Indian food. It has a high customer rating and is located near the Café in the riverside has a high price range and has a high customer rating. It has a high customer rating. <eos>\n",
      "0.4341209939049799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_type = \"greedy\"\n",
    "for idx in [100, 120]:\n",
    "    print(src_unique[idx])\n",
    "    src = src_unique[idx]\n",
    "    print(\"Geedy Search:\")\n",
    "    print(' '.join(get_cand(src_unique[idx], \"greedy\")))\n",
    "    print(get_score(src, \"greedy\", ngram = ngram))\n",
    "    print(\"Beam Search:\")\n",
    "    print(' '.join(get_cand(src_unique[idx], \"beam\")))\n",
    "    print(get_score(src, \"beam\", ngram = ngram))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
